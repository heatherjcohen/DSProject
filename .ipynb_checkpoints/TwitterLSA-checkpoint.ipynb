{
 "metadata": {
  "name": "",
  "signature": "sha256:98570c9e568a38501be546af0888fa6e0e1ed3c04e6d239e5984f683943a2441"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pymongo\n",
      "import tweepy\n",
      "import json\n",
      "from pymongo import MongoClient\n",
      "from bson.objectid import ObjectId\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "\n",
      "client = MongoClient('c621.candidate.15.mongolayer.com', 10621)\n",
      "client.twitter.authenticate('hjc', 'Iamnumber1')\n",
      "db = client.twitter\n",
      "print db.collection_names()\n",
      "print db.tweets.count()\n",
      "print db.tweets.find({'fem':1}).count() #neg\n",
      "print db.tweets.find({'fem':0}).count() #pos\n",
      "print db.tweets.find({\"fem\": {\"$exists\": False}}).count() #test\n",
      "neg_tweets = [(doc['text']) for doc in db.tweets.find({'fem':1})] \n",
      "pos_tweets = [(doc['text']) for doc in db.tweets.find({'fem':0})] \n",
      "neg_sent =  [(doc['fem']) for doc in db.tweets.find({'fem':1})] \n",
      "pos_sent = [(doc['fem']) for doc in db.tweets.find({'fem':0})] \n",
      "sent = neg_sent + pos_sent\n",
      "vect = CountVectorizer(analyzer='char_wb', ngram_range=(2, 5), encoding=u'utf-8', stop_words='english')\n",
      "ngvText = vect.fit_transform(pos_tweets + neg_tweets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'system.indexes', u'tweets', u'langs']\n",
        "30597"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "217"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "217"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "30163"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, y_train = ngvText, sent\n",
      "test_tweets =[(doc['text']) for doc in db.tweets.find({\"fem\": {\"$exists\": False}})] \n",
      "X_test = vect.transform(test_tweets)\n",
      "transformer = TfidfTransformer()\n",
      "#turns into sparse array\n",
      "X_train_tfidf = transformer.fit_transform(X_train)\n",
      "X_test_tfidf = transformer.fit_transform(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.decomposition import TruncatedSVD\n",
      "from sklearn.decomposition import PCA\n",
      "\n",
      "\n",
      "tsvd = TruncatedSVD(n_components =100)\n",
      "tsvd.fit_transform(X_train_tfidf)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "array([[ 0.32985942, -0.06934101, -0.10359772, ..., -0.00655101,\n",
        "        -0.04383362,  0.00346318],\n",
        "       [ 0.2300907 , -0.0991252 , -0.26598174, ..., -0.0049978 ,\n",
        "        -0.00041635, -0.01441005],\n",
        "       [ 0.335303  , -0.11500969, -0.22496476, ...,  0.0200516 ,\n",
        "         0.00777031,  0.01481405],\n",
        "       ..., \n",
        "       [ 0.14334745,  0.25734768, -0.00053118, ...,  0.01002545,\n",
        "         0.01286417,  0.10562106],\n",
        "       [ 0.18610766, -0.04549377, -0.00648559, ..., -0.05192373,\n",
        "        -0.0023995 ,  0.07226618],\n",
        "       [ 0.13829091,  0.20302639,  0.02656366, ...,  0.04810045,\n",
        "         0.04166834,  0.052913  ]])"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "pickle.dump( ngvText, open( \"save.p\", \"wb\" ) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "posText = vect.transform(pos_tweets)\n",
      "\n",
      "negText = vect.transform(neg_tweets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "pickle.dump( posText, open( \"pos.p\", \"wb\" ) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "pickle.dump( negText, open( \"neg.p\", \"wb\" ) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from textstat.textstat import textstat\n",
      "str1 = ''.join(pos_tweets)\n",
      "\n",
      "if __name__ == '__main__':\n",
      "               test_data = str1\n",
      "        \n",
      "a= textstat.flesch_reading_ease(test_data)\n",
      "\n",
      "b= textstat.flesch_kincaid_grade(test_data)\n",
      "\n",
      "c= textstat.coleman_liau_index(test_data)\n",
      "\n",
      "d= textstat.automated_readability_index(test_data)\n",
      "\n",
      "\n",
      "e= textstat.linsear_write_formula(test_data)\n",
      "score = (a+b+c+d+e)/5\n",
      "print score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "20.486\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from textstat.textstat import textstat\n",
      "str2 = ''.join(neg_tweets)\n",
      "\n",
      "if __name__ == '__main__':\n",
      "               test_data = str2\n",
      "        \n",
      "a= textstat.flesch_reading_ease(test_data)\n",
      "\n",
      "b= textstat.flesch_kincaid_grade(test_data)\n",
      "\n",
      "c= textstat.coleman_liau_index(test_data)\n",
      "\n",
      "d= textstat.automated_readability_index(test_data)\n",
      "\n",
      "\n",
      "e= textstat.linsear_write_formula(test_data)\n",
      "score = (a+b+c+d+e)/5\n",
      "print score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "19.488\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}